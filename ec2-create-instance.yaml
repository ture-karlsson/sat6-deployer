---
      # Open up SSH from 10.0.0.0/8 to the Satellite instance
    - name: create security group '{{ security_group_name }}
      ec2_group:
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        name: '{{ security_group_name }}'
        region: '{{ region }}'
        vpc_id: '{{ vpc_id }}'
        rules:
          # SSH 
          - proto: tcp
            from_port: 22
            to_port: 22
            cidr_ip: 10.0.0.0/8
        description: "Satellite Security Group"

      # Open upp all required ports from Client networks
      # i.e the Security Groups where the OCP Nodes resides
      # These are specified in client_network_groups
      # The rules will be applied in a loop.
    - name: edit security group '{{ security_group_name }}'
      ec2_group:
        purge_rules: false
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        name: '{{ security_group_name }}'
        region: '{{ region }}'
        vpc_id: '{{ vpc_id }}'
        rules:
          # HTTP from Dev Client Network
          - proto: tcp
            from_port: 80
            to_port: 80
            cidr_ip: '{{ item }}'
          # HTTPS from Client Network
          - proto: tcp
            from_port: 443
            to_port: 443
            cidr_ip: '{{ item }}'
          # Katello Agent AMQP from Client Network
          - proto: tcp
            from_port: 5647
            to_port: 5647
            cidr_ip: '{{ item }}'
        description: "Satellite Security Group"
      with_items: '{{ client_network_groups }}' 

    - name: create instance
      ec2:
        region: '{{ region }}'
        vpc_subnet_id: '{{ vpc_subnet_id }}'
        aws_access_key: '{{ aws_access_key }}'
        aws_secret_key: '{{ aws_secret_key }}'
        key_name: '{{ key_name }}'
        instance_type: '{{ instance_type }}'
        image: '{{ ami_id }}'
        wait: yes
        wait_timeout: 500
        count: 1
        group: '{{ security_group_name }}'
        instance_tags:
          Name: '{{ instance_name_tag }}'
        volumes:
        - device_name: /dev/xvdb
          volume_size: 50
          delete_on_termination: True
        - device_name: /dev/xvdc
          volume_size: 20
          delete_on_termination: True
        - device_name: /dev/xvdd
          volume_size: 250
          delete_on_termination: True
      register: ec2_instance

    - set_fact:
        instance_private_ip: "{{ item.private_ip }}"
      with_items: "{{ ec2_instance.instances }}"

    - debug: 
        msg: '{{ instance_private_ip }}'

# Probably something with IAM
# Have to add manually to Route53 for now
# 
#    - route53:
#        command: create
#        zone: cc.azd.cloud.allianz
#        record: satellite.cc.azd.cloud.allianz
#        type: A
#        ttl: 7200
#        value: '{{ instance_private_ip }}'
#        wait: yes

    - add_host:
        name: "{{ instance_private_ip }}"
        groups: just_created
        ansible_ssh_private_key_file: "{{ instance_ssh_private_key_file }}"
        ansible_become: True
        ansible_ssh_user: "{{ instance_ssh_user }}"
        ansible_ssh_common_args: '-o StrictHostKeyChecking=no'

    - name: wait for new instance to come up
      wait_for:
        host: "{{ instance_private_ip }}"
        port: 22
        delay: 30
        timeout: 320
        state: started

    - name: pause for user input
      pause: 
        prompt: "Now we have to add the DNS entry for {{ satellite_hostname }} on {{ instance_private_ip }} in route53. Press  Enter  when the DNS entry has been added."
        
    
 
 

